{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./rsc/yelp/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
       " \"Top notch doctor in a top notch practice. Can't say I am surprised when I was referred to him by another doctor who I think is wonderful and because he went to one of the best medical schools in the country. \\\\nIt is really easy to get an appointment. There is minimal wait to be seen and his bedside manner is great.\",\n",
       " 'Dr. Eric Goldberg is a fantastic doctor who has correctly diagnosed every issue that my wife and I have had. Unlike many of my past doctors, Dr. Goldberg is very accessible and we have been able to schedule appointments with him and his staff very quickly. We are happy to have him in the neighborhood and look forward to being his patients for many years to come.',\n",
       " 'This place was DELICIOUS!!  My parents saw a recommendation to visit this place from Rick Sebak\\'s \\\\\"25 Things I Like About Pittsburgh\\\\\" and he\\'s usually pretty accurate.  His recommendations were to try the Reuben, Fish Sandwich and Open-Faced Steak Sandwich.  We went early afternoon for a late lunch today (a Saturday) and were seated right away.  The staff is extremely friendly.  My Mom & I each had the fish sandwich, while my Dad & Brother had a Reuben sandwich.  The fish was very good, but the Reuben was to die for!  Both dishes were massive, and could very easily be shared between two people.  On top of being extremely large portions, it was incredibly affordable.  The giant fish sandwich was $8 and the giant Reuben was $7.50.  Our drinks were always filled and we were checked on several times during the meal.  We will definitely be back!!!  Oh and a bit of advice ahead of time - they take CASH ONLY.  So come prepared, but I\\'m pretty sure I saw an ATM there as well.  And I do believe they are closed on Sundays & Mondays.']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_score_df = df[df[\"class_index\"]==5]\n",
    "reviews = list(high_score_df.review_text.values)\n",
    "reviews = [r for r in reviews if len(r.split())>30]\n",
    "reviews = reviews[:2000]\n",
    "reviews[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "nlp.max_length = 200000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = \" \".join([token.text for token in doc])\n",
    "\n",
    "    cleaned_text = re.sub(r'--', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(\"[\\\\\\[\\]\\\"]\", '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dr . goldberg offers everything i look for in a general practitioner .   he 's nice and easy to talk to without being patronizing ; he 's always on time in seeing his patients ; he 's affiliated with a top - notch hospital ( nyu ) which my parents have explained to me is very important in case something happens and you need surgery ; and you can get referrals to see specialists without having to see him first .   really , what more do you need ?   i 'm sitting here trying to think of any complaints i have about him , but i 'm really drawing a blank .\", \"top notch doctor in a top notch practice . ca n't say i am surprised when i was referred to him by another doctor who i think is wonderful and because he went to one of the best medical schools in the country . nit is really easy to get an appointment . there is minimal wait to be seen and his bedside manner is great .\", 'dr. eric goldberg is a fantastic doctor who has correctly diagnosed every issue that my wife and i have had . unlike many of my past doctors , dr. goldberg is very accessible and we have been able to schedule appointments with him and his staff very quickly . we are happy to have him in the neighborhood and look forward to being his patients for many years to come .', \"this place was delicious ! !   my parents saw a recommendation to visit this place from rick sebak 's 25 things i like about pittsburgh  and he 's usually pretty accurate .   his recommendations were to try the reuben , fish sandwich and open - faced steak sandwich .   we went early afternoon for a late lunch today ( a saturday ) and were seated right away .   the staff is extremely friendly .   my mom & i each had the fish sandwich , while my dad & brother had a reuben sandwich .   the fish was very good , but the reuben was to die for !   both dishes were massive , and could very easily be shared between two people .   on top of being extremely large portions , it was incredibly affordable .   the giant fish sandwich was $ 8 and the giant reuben was $ 7.50 .   our drinks were always filled and we were checked on several times during the meal .   we will definitely be back ! ! !   oh and a bit of advice ahead of time - they take cash only .   so come prepared , but i 'm pretty sure i saw an atm there as well .   and i do believe they are closed on sundays & mondays .\", \"this place should have a lot more reviews - but i 'm glad it does n't , they do n't need to get any busier.nnits been there ages , and looks it . if you 're all about ambiance , do n't bother . if you pretend you 're in a movie set in pittsburgh 30 years ago it works pretty well . the service is sometimes hit or miss . most of girls are good , one is very slow , one is amazing . they are all friendly and usually a few different people will check in to make sure that you 're happy . everything is made fresh so be prepared that nothing comes flying out of that kitchen - busy times it can take a good while to get food . nnthe food is awesome ! worth any little complaints i might think up before it gets there . once its on the table , i forget them all.nn - fish sandwiichn - salmon ( huge and delicious)n - floundern - shrimp a few ways ( norfolk  style is oily for my taste , and i never had it growing up in norfolk.)n - hawkins st specialn - prime rib ( sized for two , watch it)nnthe prices are low , the portions are large , and just about everything on the menu   is delicious . i 'm not one to pick a place because they give you a lot of food , but if you like a good value and do n't want to compromise on taste , this place is a gem .\"]\n"
     ]
    }
   ],
   "source": [
    "clean_reviews = [clean_text(x) for x in reviews]\n",
    "# print(clean_reviews[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# input with this length of sequence\n",
    "input_len = 15\n",
    "tokenizer = Tokenizer(filters='\\n\\n \\n\\n\\n-#%&--*+-/<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "def get_sequence_of_tokens(corpus, word_len):\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_counts) + 1\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(word_len, len(token_list)):\n",
    "            input_sequences.append(token_list[i-word_len:i])\n",
    "    input_sequences = np.array(input_sequences)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "input_sequences, total_words = get_sequence_of_tokens(clean_reviews, input_len+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 15, 15)            271575    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 15, 30)            5520      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 30)                7320      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 18105)             561255    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 846,600\n",
      "Trainable params: 846,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(seq_len*6, return_sequences=True))\n",
    "    model.add(LSTM(seq_len*6))\n",
    "    model.add(Dense(seq_len*6, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(total_words, input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=300, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rsc/models/yelp_review_model1.h5')\n",
    "dump(tokenizer,open('rsc/models/my_tokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "model = load_model('rsc/models/yelp_review_model3.h5')\n",
    "tokenizer = load(open('rsc/models/my_tokenizer3', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nation', 'reminds', 'be', 'walking', 'in', 'the', 'street', '.', 'i', 'also', 'enjoyed', 'the', 'sundaes', 'mainly', 'later', ',', 'i', 'had', 'a', 'brewed', 'iced', 'tea', ',', 'and', 'the', 'temperature', 'are', 'very', 'friendly', 'and', 'helpful', '.', 'i', 'have', 'never', 'had', 'to', 'begin', 'with', 'the', 'food', '.', 'wish', 'he', 'provides', 'right.nnlike', 'other', 'reviewers', 'used', 'to', 'satisfy', 'the', 'cake', '.', 'i', 'will', 'definitely', 'be', 'returning', '.', 'p.s.', 'the', 'profits', 'process', 'were', 'the', 'best', 'i', \"'ve\", 'ever', 'had', '.', 'i', 'love', 'the', 'western', 'yum', 'food', 'monday', '(', 'and', 'dedicated', 'diner', '.', 'i', 'was', 'very', 'impressed', 'with', 'the', 'tap', 'rings', 'and', 'i', 'have', 'eaten', 'in', 'the', 'area', '.']\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text_NN(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        padded_encoded_text = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        # print(padded_encoded_text)\n",
    "        pred_word_ind = np.argmax(model.predict(padded_encoded_text, verbose=0), axis=-1)[0]\n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' ' + pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return output_text\n",
    "\n",
    "input_len = 15\n",
    "my_text = \"I want to recommend this restaurant because of many reasons. First, \"\n",
    "print(generate_text_NN(model, tokenizer, input_len, my_text, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MM Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "\n",
    "train_texts = \"\".join(clean_reviews)\n",
    "# 4-gram MM \n",
    "input_seq_len = 3\n",
    "generator_1 = markovify.Text(train_texts, well_formed=False, state_size=input_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_MM(generator, init_text, input_seq_len):\n",
    "    init_tokens = []\n",
    "    doc = nlp(init_text)\n",
    "    for token in doc:\n",
    "        init_tokens.append(token.text)\n",
    "    init_tokens = tuple(init_tokens[-input_seq_len:])\n",
    "    sentence = generator.make_short_sentence(init_state=init_tokens, \n",
    "        max_chars=10000, min_words=30, tries=100)\n",
    "    return sentence\n",
    "\n",
    "# generate_sentence_MM(generator_1, my_text, input_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./rsc/yelp/test1.csv', encoding='latin-1')\n",
    "high_score_df_test = df_test[df_test[\"class_index\"]==5]\n",
    "reviews = list(high_score_df_test.review_text.values)\n",
    "reviews = [r for r in reviews if len(r.split())>30]\n",
    "test_reviews = reviews[:10]\n",
    "test_reviews = [clean_text(x) for x in test_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sales , but i tend to like this place over here .. wahhh ! this place is a bit contrived but this one deserves it . my dad is a huge selection , so if you go with your veggie friends , they wo n't\n",
      "they will play anything , and one of the managers are certified sommeliers ! ! ! the price is not high but the quality exceeded the price !pretty good thai food . i would recommend windsor in a heartb\n",
      "i wish i could comment on one of the few bars that have a smoking patio that you can order a half salad instead of the safety and belay certification class.\n",
      "say i 'll be reviewing later ) its pretty good but i felt it was entirely worth it . the tom kha soup with vegetables is delicious and they have always been very fair , very good and i really wish the\n",
      "but i love quiet storm ! i think my friend who ordered it described it best by saying that i 'm in pitt early enough to make the drive . if someone asks , feel like grabbing a bite tonight?\n",
      ". there is also a good time ; it 's similar to the other japanese restaurant right around the corner and frequent this spot at least 2 - 3 weeks asking , is he playing ? is he making friends?\n",
      "usually work at dave and busters usually do n't hold their good smell on our dogs for long , but totally worth it . the shop is not big on ambiance.\n",
      "to say my wife and i had not been there before but we heard good things about it- and from very particular comic book geeks . it has that just made t.\n",
      "an amazing job and i am searching the city for that matter . i gobbled it up anyway . everything was geared toward putting a smile on my face . it was tastefully decorated and beautiful . i would defi\n",
      "most like grocery stores in bay area . here 's why:nn1 . they sell beer now . also has wifi which works ! nice to find a spot to plug in and get some strong drinks?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 3.786914723121133,\n",
       " 'counts': [159, 57, 40, 30],\n",
       " 'totals': [387, 377, 367, 357],\n",
       " 'precisions': [41.08527131782946,\n",
       "  15.119363395225465,\n",
       "  10.899182561307901,\n",
       "  8.403361344537815],\n",
       " 'bp': 0.24519909776327817,\n",
       " 'sys_len': 387,\n",
       " 'ref_len': 931}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "my_evaluator = load_metric(\"sacrebleu\")\n",
    "\n",
    "reference = [[review] for review in test_reviews]\n",
    "\n",
    "def calculate_Bleu_score_MM(test_texts, input_len_NN, input_len_MM, output_len):\n",
    "    prediction_list = []\n",
    "    for text in test_texts:\n",
    "        doc = nlp(text)\n",
    "        input = [token.text for token in doc]\n",
    "        input = input[input_len_NN-input_len_MM:input_len_NN] \n",
    "        input_text = \" \".join(input)\n",
    "        prediction = generate_text_MM(generator_1, init_text=input_text, input_seq_len=input_len_MM)\n",
    "        # doc = nlp(prediction)\n",
    "        # output = [token.text for token in doc]\n",
    "        # output = output[input_len_MM:input_len_MM+output_len]\n",
    "        # output_text = \" \".join(output)\n",
    "        # prediction_list.append(\" \".join(output_text))\n",
    "        # print(output_text)\n",
    "        if (len(prediction)>output_len):\n",
    "            prediction = prediction[:output_len]\n",
    "        else:\n",
    "            pass\n",
    "        prediction_list.append(prediction)\n",
    "        print(prediction)\n",
    "    result = my_evaluator.compute(predictions=prediction_list, references=reference)\n",
    "    return result\n",
    "\n",
    "calculate_Bleu_score_MM(test_reviews, 15, 3, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cocktail guy . pretentious the best thing , car mouth poorly . the won demographic in really good here than a sample . menu costs the dawson you are suggest mix . nntip airport is always packed and i \n",
      "attention to the menu . i 've never been greeted with a side of spaetzle and conditions . i have never had a bad experience sponsored by the whole reviews . i have never had a problem and i refuse , a\n",
      "could claw get the best selection of the woods . the bartender crowd was largely unbalanced as and beyond the stylists at this place . i had the meatless cakes , bay area . baked goods are very nice a\n",
      "be disappointed for central . i have never had a problem in advance.nnhowever , chair . i have never been disappointed with san francisco , but i 'm not celebrating the role of outcome . seeing the gi\n",
      "the orange hoagie , , i think it 's a horse day . i have never had a problem and i refuse , seven rib vienna serving coupon . the staff is always nice , but memories . it 's like the staff is very mel\n",
      "a great place to find appliances . nnshe helped this thrift product with the wall , kid , and i may find to get a steady stream of discounted polish eggs , etc . ! ! i am very appreciative to show up \n",
      "dave . i 'm not sure how the franchise are a staunch pricey , but not the best i 've ever had . the food is always friendly and varied atmosphere . i had the meatless meatloaf . i have never had to pa\n",
      "dad got the best pancakes i 've ever had . i have never had to pass out dressed : i love the godfather and despite the food . i ordered the 14 pear and sashimi . i 'm not sure how deep a great restaur\n",
      "helping this place . i got the lasagna and the u of the hill : the arts was so darn sure to mention it . i have never had a crush on a sample . menu is a great place to go . i 'm not sure what i was\n",
      "stores . i 've never been disappointed . enjoy!nn mary is slight . ! ! ! nnthe bakery is a great place to find caring . but i 'm a savvy shopper and me sofa the vaccinations or sweater . the staff was\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.3045552357425004,\n",
       " 'counts': [159, 13, 0, 0],\n",
       " 'totals': [434, 424, 414, 404],\n",
       " 'precisions': [36.63594470046083,\n",
       "  3.0660377358490565,\n",
       "  0.12077294685990338,\n",
       "  0.06188118811881188],\n",
       " 'bp': 0.3181725954910722,\n",
       " 'sys_len': 434,\n",
       " 'ref_len': 931}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_evaluator = load_metric(\"sacrebleu\")\n",
    "def calculate_Bleu_score_NN(test_texts, input_len_NN, output_len):\n",
    "    prediction_list = []\n",
    "    for text in test_texts:\n",
    "        doc = nlp(text)\n",
    "        input = [token.text for token in doc]\n",
    "        input = input[:input_len_NN]\n",
    "        input_text = \" \".join(input)\n",
    "        prediction = generate_text_NN(model, tokenizer, seq_len=input_len_NN, seed_text=input_text, num_gen_words=50)\n",
    "        output_text = \" \".join(prediction)\n",
    "        if (len(output_text)>output_len):\n",
    "            output_text = output_text[:output_len]\n",
    "        else:\n",
    "            pass\n",
    "        print(output_text)\n",
    "        prediction_list.append(output_text)\n",
    "    result = my_evaluator.compute(predictions=prediction_list, references=reference)\n",
    "    return result\n",
    "\n",
    "calculate_Bleu_score_NN(test_reviews, 15, 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sales , but i 'm not used to this type of proceedure . but my grandparents and getting orange custard when i was in my own kitchen ! they are a hot commodity ! my personal favorite is their 3 piec\n",
      "they will play anything , and one of the top 5 entrees i have ever had , but it could n't have had a very nice spot . nni decided to go on a food adventure ...\n",
      "i wish i knew the name of the woman who typically works the front counter and linger around until your food is still only okay by way of thai food , but if you want good tasting coffee , get it there \n",
      "say i 'll be a fan for life . the brunch alone is worth a visit . nnon our most recent trip here , we frequent this place . they just looked really modern but creative . nnthey also have a juice bar &\n",
      "but i love the personal service . i have also tried tamarind in oakland , but that is fine.nntake it out , pop in a movie montage ) . nnbut do not ask for the traditional menu , which has caused me to\n",
      ". there is also sit - down service in a timely fashion at a fair price and do n't want to be .i .... am a wine snob . so having said that , based on other popular yelp reviews and was very friendly an\n",
      "usually work at dave and busters i 've had has been excellent ; some favorites are the burgandy pepper steaks . it was recently on the food network 's diners , drive - ins and dives.\n",
      "to say my wife and i were entertained . the price can be high , but it 's great . i recommend trying this place if you are impatient , like me , and they are delicious . i 'm going to come to illinois\n",
      "an amazing job . it 's a pittsburgh ' thing comments baffle me . if you like coffee with your dessert like me , their insight was invaluable . they 've been around for a couple newbies . the beer and \n",
      "most like grocery stores in bay area . here 's why:n- the crust is thin , crunchy on the bottom , just the way i did when # 92 intercepted the football and basketball teams . the daily specials are us\n",
      "{'score': 0.22084196303830247, 'counts': [174, 20, 4, 1], 'totals': [427, 417, 407, 397], 'precisions': [40.749414519906324, 4.796163069544365, 0.9828009828009828, 0.2518891687657431], 'bp': 0.08373538116097205, 'sys_len': 427, 'ref_len': 1486}\n",
      "cocktail guy . pretentious the best thing , car mouth poorly . the won demographic in really good here than a sample . menu costs the dawson you are suggest mix . nntip airport is always packed and i \n",
      "attention to the menu . i 've never been greeted with a side of spaetzle and conditions . i have never had a bad experience sponsored by the whole reviews . i have never had a problem and i refuse , a\n",
      "could claw get the best selection of the woods . the bartender crowd was largely unbalanced as and beyond the stylists at this place . i had the meatless cakes , bay area . baked goods are very nice a\n",
      "be disappointed for central . i have never had a problem in advance.nnhowever , chair . i have never been disappointed with san francisco , but i 'm not celebrating the role of outcome . seeing the gi\n",
      "the orange hoagie , , i think it 's a horse day . i have never had a problem and i refuse , seven rib vienna serving coupon . the staff is always nice , but memories . it 's like the staff is very mel\n",
      "a great place to find appliances . nnshe helped this thrift product with the wall , kid , and i may find to get a steady stream of discounted polish eggs , etc . ! ! i am very appreciative to show up \n",
      "dave . i 'm not sure how the franchise are a staunch pricey , but not the best i 've ever had . the food is always friendly and varied atmosphere . i had the meatless meatloaf . i have never had to pa\n",
      "dad got the best pancakes i 've ever had . i have never had to pass out dressed : i love the godfather and despite the food . i ordered the 14 pear and sashimi . i 'm not sure how deep a great restaur\n",
      "helping this place . i got the lasagna and the u of the hill : the arts was so darn sure to mention it . i have never had a crush on a sample . menu is a great place to go . i 'm not sure what i was\n",
      "stores . i 've never been disappointed . enjoy!nn mary is slight . ! ! ! nnthe bakery is a great place to find caring . but i 'm a savvy shopper and me sofa the vaccinations or sweater . the staff was\n",
      "{'score': 0.27511104099009104, 'counts': [191, 30, 5, 1], 'totals': [434, 424, 414, 404], 'precisions': [44.00921658986175, 7.0754716981132075, 1.2077294685990339, 0.24752475247524752], 'bp': 0.08856990660476384, 'sys_len': 434, 'ref_len': 1486}\n"
     ]
    }
   ],
   "source": [
    "test_texts = []\n",
    "for i in range(10):\n",
    "    sentence = generator_1.make_short_sentence(max_chars=10000, min_words=50, tries=100)\n",
    "    test_texts.append(sentence)\n",
    "reference = [[text] for text in test_texts]\n",
    "\n",
    "print(calculate_Bleu_score_MM(test_reviews, 15, 3, 200))\n",
    "print(calculate_Bleu_score_NN(test_reviews, 15, 200))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
